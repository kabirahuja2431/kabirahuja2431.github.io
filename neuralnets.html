<!DOCTYPE html>
<html lang="en">

  <head>

    <!-- Meta Tag -->
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">

    <!-- SEO -->
    <meta name="description" content="150 words">
    <meta name="author" content="uipasta">
    <meta name="url" content="http://www.yourdomainname.com">
    <meta name="copyright" content="company name">
    <meta name="robots" content="index,follow">
    <meta property="og:site_name" content="kabirahuja2431.github.io"/>
    <meta property="og:title" content="Neural Networks: Why thou so Powerful!"/>
    <meta property="og:description" content="Hi guys, Today's blog will be a little different from my other blogs, today we won't learn how to do something cool with neural nets, but instead we will see what makes Neural Networks so great for machine learning problems."/>
    <meta property="og:image" content="images/neuralnets/export.png">
    <meta property="og:url" content="https://kabirahuja2431.github.io/neuralnets.html">
    <meta property="og:type" content="blog"/>
    <title>Neural Nets</title>

    <!-- Favicon -->
    <link rel="shortcut icon" href="images/favicon/favicon.ico">
    <link rel="apple-touch-icon" sizes="144x144" type="image/x-icon" href="images/favicon/apple-touch-icon.png">

    <!-- All CSS Plugins -->
    <link rel="stylesheet" type="text/css" href="css/plugin.css">

    <!-- Main CSS Stylesheet -->
    <link rel="stylesheet" type="text/css" href="css/style.css">

    <!-- Google Web Fonts  -->
    <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Poppins:400,300,500,600,700">

    <!-- Syntax Highlighter  -->
    <link rel="stylesheet" type="text/css" href="css/syntax/shCore.css">
    <link rel="stylesheet" type="text/css" href="css/syntax/shThemeDefault.css">

    <script type="text/javascript" async
    src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML">
    </script>
    <!-- HTML5 shiv and Respond.js support IE8 or Older for HTML5 elements and media queries -->
    <!--[if lt IE 9]>
	   <script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
	   <script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
    <![endif]-->


  </head>

 <body>



	 <!-- Preloader Start -->
     <div class="preloader">
	   <div class="rounder"></div>
      </div>
      <!-- Preloader End -->




    <div id="main">
        <div class="container">
            <div class="row">



                 <!-- About Me (Left Sidebar) Start -->
                 <div class="col-md-3">
                   <div class="about-fixed">

                     <div class="my-pic">
                        <img src="images/kab.jpg" alt="">
                        </div>



                      <div class="my-detail">

                        <div class="white-spacing">
                            <h1>Kabir Ahuja</h1>
                            <span>Deep Learning Enthusiast</span>
                        </div>

                       <ul class="social-icon">
                         <li><a href="https://www.facebook.com/kabirahuja31" target="_blank" class="facebook"><i class="fa fa-facebook"></i></a></li>
                         <li><a href="https://www.linkedin.com/in/kabir-ahuja-aa1942123/" target="_blank" class="linkedin"><i class="fa fa-linkedin"></i></a></li>
                         <li><a href="https://github.com/kabirahuja2431" target="_blank" class="github"><i class="fa fa-github"></i></a></li>
                        </ul>

                    </div>
                  </div>
                </div>
                <!-- About Me (Left Sidebar) End -->





                 <!-- Blog Post (Right Sidebar) Start -->
                 <div class="col-md-9">
                    <div class="col-md-12 page-body">
                    	<div class="row">


                            <div class="sub-title">
                           		<a href="index.html" title="Go to Home Page"><h2>Back Home</h2></a>
                                <a href="#comment" class="smoth-scroll"><i class="icon-bubbles"></i></a>
                             </div>


                            <div class="col-md-12 content-page">
                              <div class="col-md-12 blog-post">


                                <!-- Post Headline Start -->
                                <div class="post-title">
                                    <h1>Neural Networks: Why thou so Powerful!</h1>
                                   </div>
                                   <!-- Post Headline End -->


                                <!-- Post Detail Start -->
                                <div class="post-info">
                                    <span>August 22, 2017 / by <a href="#" target="_blank">Kabir Ahuja</a></span>
                                   </div>
                                   <!-- Post Detail End -->


                                    <p>Hi guys, Today's blog will be a little different from my other blogs, today we won't learn how to do something cool with neural nets, but instead we will see what makes Neural Networks so great for machine learning
                                    problems. This post is for the people who know what neural nets are but find it difficult to understand why they work so well. I will take an example of binary classification to demonstrate how neural nets
                                    are able to approximate highly complex functions accurately. So lets dive into the details, its going to be fun.
                                    </p>
                                   <h2> Binary Classification </h2>
                                   <img src="images/neuralnets/data.png" class = 'nn'>
                                   <p>As you can see from the figure we are given a set of points and some are yellow and other are blue demostrating the different classes(or categories) to which the points belong. Our job is to learn from this data so that given a new point we can predict its class accurately.<br>
                                   The simplest approach to this problem is using a Linear Classifier. What a Linear Classifier does is, it learns a line (known as a decision boundary) which seperates the data points, such that points lying on one side belongs to one class and points lying on the other side belongs to the other class. Like in our problem, what a linear classifier will do is find a line which separates the blue and yellow points.<br>
                                   Now as we can see from the plot, it is impossible to find a line which can separate these points perfectly. I trained a softmax classifier on these data points and got the following plot.
                                   <img src="images/neuralnets/myfig.png" class = 'nn'>
                                   <br>
                                   As we can see from the plot, the decision boundary is not able to separate the points belonging to different classes properly, there are many yellow points in the region of blue and vice versa. Hence a linear classifier isn't a good choice for solving this problem. Neural Networks however can solve this problem with much higher accuracy.There are two ways to think why they perform so well. Lets see them.
                                   </p>

                                  <h2>First Idea: Making the data linearly separable</h2>
                                  <p>
                                  As we saw above, a linear function wasnt able to separate the data points we had, but what if I transform these points in such a way that they become linearly separable? We can think of neural networks as doing the same thing.
                                  There are two important components of a neural network, a) Hidden Layers b) Hidden units in each layer. We call these hidden units as 'neurons'.Below is a figure comparing architectures of a linear classifier and a neural network.
                                  </p>
                                  <div class="mxgraph" style="max-width:100%;border:1px solid transparent;" data-mxgraph="{&quot;highlight&quot;:&quot;#0000ff&quot;,&quot;nav&quot;:true,&quot;resize&quot;:true,&quot;toolbar&quot;:&quot;zoom layers lightbox&quot;,&quot;edit&quot;:&quot;_blank&quot;,&quot;xml&quot;:&quot;&lt;mxfile userAgent=\&quot;Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.36\&quot; version=\&quot;7.1.8\&quot; editor=\&quot;www.draw.io\&quot; type=\&quot;device\&quot;&gt;&lt;diagram id=\&quot;9f9ec519-4e2e-932b-25ee-d0e356dcaa15\&quot; name=\&quot;Page-1\&quot;&gt;7Vxbd6M2EP41fuwekJCAxyS77fac7eWcPLR91BrZ5gSDCzi2++srjLBhhqQx5qK42YcsjEBC3zczmtHFM/qw3v+Uis3qlySQ0YxYwX5GP88I8Vyi/haCQymgDi8FyzQMSpF9FjyG/0gttLR0GwYyazyYJ0mUh5umcJ7EsZznDZlI02TXfGyRRM1WN2IpkeBxLiIs/SMM8pWW2tw/F3yV4XKlm/aIWxZ8F/OnZZpsY93ejNDF8V9ZvBZVXbqj2UoEya4mol9m9CFNkry8Wu8fZFRAW8FWvvfjC6Wn705lnL/lBc3Ts4i2uut7XUeWHyo01CsKeHVzv1uFuXzciHlRslPUK9kqX0fqzlaXItuUbCzCvVQt3OvaZZrL/YtfaJ/6rdRJJmuZpwf1iH7B10hpTTqpyO7Mi6tFqxojlUxoTVieKj6joS40IO3gUAwOMRocSscDhyNwMDRxcFcYo7qLk1g24SiflgEyxP/se61zrKVzlSyVkcjD52b1bT3WLfyehKrhE7Q2B4rHAGhZsk3nUr9VNzFQEbUASRaoKBfpUuaoIgWdONQe2xQPZIiiEzBvYs0diTXlr4+90u7RJCKpNzKRHWjyEE0HsxwPxIJw7Hm8Fk4h9l08j9+iwzxSDdwH4bO6XObHPpaiRXKk8Iwb/3ubVAU/ZMfI4049QNhmfy6savkWxlKkVV3qw8rqmk0ocUvDvX/LQySyLFyE8tLvAXqjSM+bCpLlafIkH5IoSc9GvwijCIhEFC5jdTtXSqK+gt4XKhSqqOlOF6zDIIhe0sgetA75ZB9rnd+idbQHraviDoNDJUYZGLIYgoe3wMP7gKclkjQsWILw0DHhcUYaeKcaZZkPdM9j3UZZlwAbt0FF/Y2yVc2dSZH7MP+zdv2XurY+sYvipBKXuo+ZikIO4xvWF4V8OApxpHRbdgVJ6c2uKBmOlLYI7SK7ilVbhWFZ1U0Xy6pnIMS5TRLdwUgkON4ZxrIAUewmiXKc4YiyEVHCNiwyhXDYHg69XqP1mtCr0tsGPoaFpmjEdEbEB09zCpuajQ+1RsQHh+6iCueNxYePiA+OokUVWZuKj9MyUT4YPtfOlA8QDRmVKtKugyx3QEV0uEH22onzAUgkU5KIksXOkRIFQx+xBiNxrGQREEVvkyg4l98jUR8J5GAk2p+4+ipuew6xHNdtVut4nzzOKWMeo5bNGR+K4UqXBmG492k50qIP0+apNtAHvyejdoZb06Q4T72Q8p5pnTYKcl3gTuE891sp9KFfhrrQI4Xkg8I6hR4MXXqiELn3HinE2f5lFL6VKGPsCm52MtGurl0d7N2uJs0tkF113bEzpl1Nv5ZoisVRuN3CRLqunpTp2+ImTRKhxVHnHTjNq6dkbsfi/HdA17WTL71b3KQZPbQ4lHiZ6DSvnpa5GYtzmGe8xVU+3ByLm3TOBFlc1+1NI1qcQxCF4oSsIWtrPly7rkylRmu1UFOnFe6I6LK25rSsXbdp+aT4VHvUXtl2OtTaI8P6c5kLMN0v+7y5BKiMs5tR2xYDVj3cYiK79TkYyAp9F6zgSRjDDt3YFhx5RtwGw/AEx8/xZluQ9U0cikMpAKqpzpkUR2L0ieICzF5ODoCNBraPcXdacO/j3AnDedNX1X0Zn4G3cERwQ+C7YO3TZji+aDtqBvcRdAIfZzwIfOy7bwh836LN8ZVizR8KfI7zl9+2+f/E5ShfDyIbTkfzObwtQLn6WKNNXjtiaX2cbyS+07Q2SrCrG+p8I8fjeys1hqA9iMk1BxrmvA39Xnxd23oEF+uiq/H3rPivKI70mPOr3KYiOl7kuyR9MpaWIExVGBwmxYs7meX9MMVBVsBaQgK77YcvOlClbs8/x1KmFeefvKFf/gU=&lt;/diagram&gt;&lt;/mxfile&gt;&quot;}"></div>
<script type="text/javascript" src="https://www.draw.io/js/viewer.min.js"></script>
                                  <p>
                                     So what happens is that we take our input, pass it to the neural network and in the final hidden layer we have a linear classifier.
                                  Hence instead of directly feeding it to the linear classifier we first pass it through our neural network and then the activations at last hidden layer are fed to the linear classifier.While we are training the network, it learns how to transform the input so that it becomes linearly separable.
                                  I built a neural net like shown in the figure in tensorflow, trained it for 100000 iterations and then ploted the activations at the last year. Have a look.</p>
                                  <img src="images/neuralnets/lsepro.png" class = 'nn'> 
                                  <p>As you can see that, the data points can now be separated easily by a line. Hence one way to think why neural networks works so well is by thinking that they transform the input into a form which is linearly separable.I hope this gave you some intuition on how neural nets works.Now lets see another way of looking at the same thing.
                                  </p>
                                  <h2>Second Idea: Neural Nets learn complex decision boundaries</h2>
                                  <p>
                                  Dont get confused that in the previous section I said that neural nets make the input linearly separable than why I am saying that they learn complex decision boundaries. What I mean is that they learn linear decision boundaries with respect to the "final hidden layer" not the input.If we plot a decision boundary with respect to the input we get a non linear curve separating the points.I trained a neural network with 1 hidden layer and 4 hidden units and ploted the decision boundary.Here is how it looks.</p>
                                  <img src="images/neuralnets/dbnn4.png" class = 'nn'> 
                                 <p>
                                 As we can see our neural net managed to learn a decision boundary which can separate the data points accurately.The decision boundary looks like a collection of lines of different slopes and intercepts.But how did it learn such a decision boundary? Lets see why.<br>
                                 A hidden unit of a neural network is calculated as the dot produt of the set of the weights with the input (or the activations of the previous layer) and then an activation function is applied on the value to get the activation. The most commonly used activation function is 'Rectified Linear Unit'(RELU) and what it does is that it takes the max of the value with zero i.e
                                 <b> a = max(0,w*x)</b>.<br>
                                 Hence a neural network can learn different linear functions by setting some neurons (or hidden units)
                                 to zero for certain values of inputs.The figure below demonstrates this thing.Red hidden units means that the value of their activations is zero.
                                  </p>
                                    <img src="images/neuralnets/export.png" class = 'export'>
                                    <br>
                                   <p>
                                   As we can see from the figure, in the first case all the hidden units except the first one are off hence the input only passes from the first unit to the output,whereas in the second case all hidden units are off except the second one. This means that a neural net can learn to turn on or off certain neurons for certain values and hence learn different linear functions for different ranges of values.This is the reason why a neural network manages to learn very complex decision boundaries.Please note that it isnt necessary to have only one neuron activated at a time, I just used it to demonstrate the fact that a neural network can learn different linear functions for different values. I also tried different values of hidden units and got the following results.

                                 </p>
                                 <div class="row margin-top-40 margin-bottom-40">

                                        <div class="col-md-4 col-sm-6 col-xs-12">
                                          <h4>4 hidden units</h4>
                                          <img src="images/neuralnets/dbnn4.png" class="img-responsive" alt="nndb4" style="width:256px;height:196px">

                                        </div>

                                        <div class="col-md-4 col-sm-6 col-xs-12">
                                            <h4>5 hidden units </h4>
                                          <img src="images/neuralnets/nndb5.png" class="img-responsive" alt="nndb5" style="width:256px;height:196px">

                                        </div>

                                       <div class="col-md-4 col-sm-6 col-xs-12">
                                          <h4>10 hidden units</h4>
                                         <img src="images/neuralnets/nndb10.png" class="img-responsive" alt="nndb10" style="width:256px;height:196px">

                                       </div>

                                     </div>
                                 <!-- Post Coding (SyntaxHighlighter) Start -->
                                <!-- Post Coding (SyntaxHighlighter) End -->
          
                                <p>
                                Then I tried a different dataset and trained neural network models with different number of hidden units.
                                </p>
                                <div class="row margin-top-40 margin-bottom-40">

                                        <div class="col-md-4 col-sm-6 col-xs-12">
                                          <h4>Dataset</h4>
                                          <img src="images/neuralnets/circle.png" class="img-responsive" alt="data" style="width:256px;height:196px">

                                        </div>

                                        <div class="col-md-4 col-sm-6 col-xs-12">
                                            <h4>5 hidden units </h4>
                                          <img src="images/neuralnets/5.png" class="img-responsive" alt="nndb5" style="width:256px;height:196px">

                                        </div>

                                       <div class="col-md-4 col-sm-6 col-xs-12">
                                          <h4>15 hidden units</h4>
                                         <img src="images/neuralnets/15.png" class="img-responsive" alt="15" style="width:256px;height:196px">

                                       </div>

                                     </div>
                                  <!-- Post Coding (SyntaxHighlighter) Start -->
                                  <h2>Conclusion</h2>
                                  <p>
                                    Today we saw the reasons why neural networks works so well on machine learning problems.I will like to mention one thing though that due to a lot of flexibility to learn different non linear functions it is very easy for neural networks to overfit the data. Remember with great power (neural nets) comes great responsibilies(to prevent overfiting). Hence we need to be careful and choose different regularization techniques like L2 and dropout while training our models. I hope that this post gave you some intuition about neural nets. You can check the code I used for training and visualizing decision boundaries <a href="https://github.com/kabirahuja2431/My-projects/tree/master/NeuralNetsVisualizations">right here</a></li> So thats it for today, see you guys next time. :)
                                  </p>

                       <h2>References</h2>

                         <ul style="list-style-type:disc">
                           <li><a href="https://medium.com/ml-algorithms/neural-networks-for-decision-boundary-in-python-b243440fb7d1">Neural Networks for Decision Boundary in Python!.</a></li>
                         </ul>




                                  <!-- Post Blockquote Start -->


                                   </div>
                                   <!-- Post Comment (Disqus) End -->



                                </div>
                             </div>

                         </div>
                       <!-- Footer Start -->
                       <div class="col-md-12 page-body margin-top-50 footer">
                          <footer>
                          <ul class="menu-link">
                            <li><a href="index.html">Home</a></li>
                            <li><a href="contact.html">Contact</a></li>
                            </ul>

                          <p>© Copyright 2016 DevBlog. All rights reserved</p>


						  <!-- UiPasta Credit Start -->
                          <div class="uipasta-credit">Design By <a href="http://www.uipasta.com" target="_blank">UiPasta</a></div>
                          <!-- UiPasta Credit End -->


                         </footer>
                       </div>
                       <!-- Footer End -->


                  </div>
                  <!-- Blog Post (Right Sidebar) End -->

            </div>
         </div>
      </div>



    <!-- Back to Top Start -->
    <a href="#" class="scroll-to-top"><i class="fa fa-long-arrow-up"></i></a>
    <!-- Back to Top End -->


    <!-- All Javascript Plugins  -->
    <script type="text/javascript" src="js/jquery.min.js"></script>
    <script type="text/javascript" src="js/plugin.js"></script>

    <!-- Main Javascript File  -->
    <script type="text/javascript" src="js/scripts.js"></script>

    <!-- Syntax Highlighter Javascript File  -->
    <script type="text/javascript" src="js/syntax/shCore.js"></script>
    <script type="text/javascript" src="js/syntax/shBrushCss.js"></script>
    <script type="text/javascript" src="js/syntax/shBrushJScript.js"></script>
    <script type="text/javascript" src="js/syntax/shBrushPerl.js"></script>
    <script type="text/javascript" src="js/syntax/shBrushPhp.js"></script>
    <script type="text/javascript" src="js/syntax/shBrushPlain.js"></script>
    <script type="text/javascript" src="js/syntax/shBrushPython.js"></script>
    <script type="text/javascript" src="js/syntax/shBrushRuby.js"></script>
    <script type="text/javascript" src="js/syntax/shBrushSql.js"></script>
    <script type="text/javascript" src="js/syntax/shBrushVb.js"></script>
    <script type="text/javascript" src="js/syntax/shBrushXml.js"></script>

	<!-- Syntax Highlighter Call Function -->
	<script type="text/javascript">
		SyntaxHighlighter.config.clipboardSwf = 'js/syntax/clipboard.swf';
		SyntaxHighlighter.all();
	</script>


   </body>
 </html>
